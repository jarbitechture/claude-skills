#!/usr/bin/env python3
"""
Report Generator for NMA Appraisal Results

Generates markdown checklist reports and YAML structured outputs
from appraisal results.
"""

from pathlib import Path
from typing import Dict, List
from datetime import datetime
import yaml
import json


class MarkdownReportGenerator:
    """Generate human-readable markdown appraisal reports"""

    @staticmethod
    def generate(
        appraisal_results: Dict,
        pdf_metadata: Dict,
        output_path: Path
    ):
        """
        Generate comprehensive markdown report

        Args:
            appraisal_results: Dict with sections and item ratings
            pdf_metadata: PDF metadata dict
            output_path: Where to save report
        """
        report = f"""# Network Meta-Analysis Appraisal Report

## Paper Information
- **Title**: {pdf_metadata.get('extracted_title', 'N/A')}
- **Pages**: {pdf_metadata.get('page_count', 'N/A')}
- **Appraisal Date**: {datetime.now().strftime('%Y-%m-%d')}

## Executive Summary

### Overall Quality Ratings
"""

        # Add section ratings
        for section in appraisal_results.get('sections', []):
            satisfactory = sum(1 for item in section['items'] if item['rating'] == '✓')
            total = len(section['items'])
            pct = (satisfactory / total * 100) if total > 0 else 0

            report += f"- **{section['name']}**: {satisfactory}/{total} ({pct:.0f}%) satisfactory\n"

        report += "\n---\n\n## Detailed Checklist\n\n"

        # Add each section
        for section in appraisal_results.get('sections', []):
            report += f"### {section['name']}\n\n"
            report += "| ID | Criterion | Rating | Evidence | Confidence |\n"
            report += "|------|-----------|--------|----------|------------|\n"

            for item in section['items']:
                criterion = item['criterion'][:60] + "..." if len(item['criterion']) > 60 else item['criterion']
                evidence = item.get('evidence', '')[:40] + "..." if len(item.get('evidence', '')) > 40 else item.get('evidence', 'N/A')

                report += f"| {item['id']} | {criterion} | {item['rating']} | {evidence} | {item.get('confidence', 'N/A')} |\n"

            report += "\n"

        # Add recommendations
        report += """---

## Recommendations

### For Decision Makers
- [ ] Accept findings with high confidence
- [ ] Accept findings with moderate confidence
- [ ] Accept findings with low confidence
- [ ] Do not use for decision-making

### For Authors/Reviewers
- [ ] Publication-ready
- [ ] Minor revisions needed
- [ ] Major revisions needed
- [ ] Reject

---

*Report generated by Network Meta-Analysis Appraisal Skill*
"""

        output_path.write_text(report)
        print(f"✓ Markdown report saved: {output_path}")


class YAMLReportGenerator:
    """Generate machine-readable YAML reports"""

    @staticmethod
    def generate(
        appraisal_results: Dict,
        pdf_metadata: Dict,
        output_path: Path
    ):
        """
        Generate structured YAML report

        Args:
            appraisal_results: Dict with sections and item ratings
            pdf_metadata: PDF metadata dict
            output_path: Where to save report
        """
        report_data = {
            'meta': {
                'appraisal_date': datetime.now().isoformat(),
                'checklist_version': '1.0',
                'frameworks_applied': [
                    'PRISMA-NMA',
                    'NICE DSU TSD 7',
                    'ISPOR-AMCP-NPC',
                    'CINeMA'
                ],
                'pdf_metadata': pdf_metadata
            },
            'ratings': {},
            'summary': {
                'total_items': 0,
                'satisfactory_count': 0,
                'concerns_count': 0,
                'deficiency_count': 0
            }
        }

        # Process sections
        for section in appraisal_results.get('sections', []):
            section_id = section['id']
            report_data['ratings'][section_id] = {}

            for item in section['items']:
                report_data['ratings'][section_id][item['id']] = {
                    'rating': item['rating'],
                    'confidence': item.get('confidence', 'N/A'),
                    'evidence': item.get('evidence', ''),
                    'source': item.get('source', '')
                }

                # Update summary
                report_data['summary']['total_items'] += 1
                if item['rating'] == '✓':
                    report_data['summary']['satisfactory_count'] += 1
                elif item['rating'] == '⚠':
                    report_data['summary']['concerns_count'] += 1
                elif item['rating'] == '✗':
                    report_data['summary']['deficiency_count'] += 1

        output_path.write_text(yaml.dump(report_data, default_flow_style=False, sort_keys=False))
        print(f"✓ YAML report saved: {output_path}")


def main():
    """Command-line interface"""
    import argparse

    parser = argparse.ArgumentParser(description='Generate appraisal reports')
    parser.add_argument('results_json', type=Path, help='Appraisal results JSON')
    parser.add_argument('--format', choices=['markdown', 'yaml', 'both'], default='both')
    parser.add_argument('--output-dir', type=Path, default=Path('.'))

    args = parser.parse_args()

    # Load results
    results = json.loads(args.results_json.read_text())
    pdf_meta = results.get('pdf_metadata', {})
    appraisal = results.get('appraisal', {})

    # Generate reports
    if args.format in ['markdown', 'both']:
        MarkdownReportGenerator.generate(
            appraisal,
            pdf_meta,
            args.output_dir / 'nma_appraisal_report.md'
        )

    if args.format in ['yaml', 'both']:
        YAMLReportGenerator.generate(
            appraisal,
            pdf_meta,
            args.output_dir / 'nma_appraisal_report.yaml'
        )


if __name__ == '__main__':
    main()
